# app.py (ìµœì¢… ì•ˆì •í™” ë²„ì „)

import streamlit as st
import pandas as pd
import json
import re
import os
import base64
from datetime import datetime
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_core.messages import HumanMessage

# --- 1. ê¸°ë³¸ ì„¤ì • ë° ëª¨ë¸/DB ë¡œë“œ ---
st.set_page_config(page_title="AI ì„¸ê´€ ì„œë¥˜ ìë™ ê²€í†  ì‹œìŠ¤í…œ", page_icon="ğŸ¤–")

@st.cache_resource
def load_resources():
    try:
        embeddings_model = OpenAIEmbeddings()
        vectordb = Chroma(persist_directory='./customs_rules_db', embedding_function=embeddings_model)
        llm = ChatOpenAI(model_name="gpt-4o", temperature=0)
        return vectordb, llm
    except Exception as e:
        st.error(f"AI ë¦¬ì†ŒìŠ¤ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. OPENAI_API_keyê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None, None

@st.cache_data
def load_rule_sheet(path):
    try:
        df = pd.read_excel(path, sheet_name='Sheet1')
        return df
    except FileNotFoundError:
        st.error(f"ê·œì¹™ íŒŒì¼({path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. customs_app í´ë”ì— íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None

# --- 2. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ë“¤ ---
def encode_image_to_base64(image_bytes):
    return base64.b64encode(image_bytes).decode('utf-8')

def parse_image_to_json_text(image_bytes, llm):
    """GPT-4o Visionìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì›ë³¸ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ë°˜í™˜"""
    base64_image = encode_image_to_base64(image_bytes)
    message = HumanMessage(
        content=[
            {"type": "text", "text": "ì´ ì´ë¯¸ì§€ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ì…ì‹ ê³ ì„œì…ë‹ˆë‹¤. ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬, ê° í•­ëª©ì— ë§ëŠ” ë°ì´í„°ë¥¼ ì¶”ì¶œí•œ í›„, ìš”ì²­í•˜ëŠ” JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ì—†ëŠ” ì •ë³´ëŠ” null, ë‚ ì§œëŠ” YYYYMMDD, ìˆ«ìëŠ” ì½¤ë§ˆ ì—†ì´ ë³€í™˜í•´ì£¼ì„¸ìš”. ë¶€ê°€ ì„¤ëª… ì—†ì´ JSON ê°ì²´ë§Œ ì‘ë‹µí•˜ì„¸ìš”. [ìš”ì²­í•˜ëŠ” JSON í˜•ì‹] {\"ì„œë¥˜ì¢…ë¥˜\": \"ìˆ˜ì…ì‹ ê³ ì„œ\", \"í•„ë“œ\": {\"â‘ ì‹ ê³ ë²ˆí˜¸\": \"string\", \"â‘¡ì‹ ê³ ì¼\": \"string\", \"â‘©ìˆ˜ì…ì\": {\"ìƒí˜¸\": \"string\", \"ìˆ˜ì…ìêµ¬ë¶„\": \"string\"}, \"â‘ªë‚©ì„¸ì˜ë¬´ì\": {\"ìƒí˜¸\": \"string\"}, \"ãŠ¼ê²°ì œê¸ˆì•¡\": {\"ì¸ë„ì¡°ê±´\": \"string\"}}} "},
            {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{base64_image}"}}
        ]
    )
    response = llm.invoke([message])
    return response.content

def validate_document(data, rules_df):
    errors = []
    fields = data.get('í•„ë“œ', {})
    importer_name = fields.get('â‘©ìˆ˜ì…ì', {}).get('ìƒí˜¸')
    if not importer_name:
        errors.append({"field_name": "ìˆ˜ì…ì ìƒí˜¸", "user_value": "ì—†ìŒ(null)", "error_message": "í•„ìˆ˜ í•­ëª©ì¸ ìˆ˜ì…ì ìƒí˜¸ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."})
    
    importer_category = fields.get('â‘©ìˆ˜ì…ì', {}).get('ìˆ˜ì…ìêµ¬ë¶„')
    taxpayer_name = fields.get('â‘ªë‚©ì„¸ì˜ë¬´ì', {}).get('ìƒí˜¸')
    if importer_name and taxpayer_name and importer_name == taxpayer_name and importer_category == 'B':
        errors.append({"field_name": "ìˆ˜ì…ì êµ¬ë¶„", "user_value": importer_category, "error_message": "ìˆ˜ì…ìì™€ ë‚©ì„¸ì˜ë¬´ì ì •ë³´ê°€ ë™ì¼í•˜ì§€ë§Œ 'B'(ìƒì´)ë¡œ ì‹ ê³ ë˜ì—ˆìŠµë‹ˆë‹¤."})
        
    return errors

def get_intelligent_error_report(error_info, vectordb, llm):
    context_from_db = "ê´€ë ¨ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"
    if vectordb:
        retrieved_docs = vectordb.similarity_search(error_info["field_name"], k=1)
        if retrieved_docs: context_from_db = retrieved_docs[0].page_content
    template = "ë‹¹ì‹ ì€ ë² í…Œë‘ ê´€ì„¸ì‚¬ì…ë‹ˆë‹¤. ì˜¤ë¥˜ í•­ëª©: {field}, ì‚¬ìš©ìì˜ ì…ë ¥ê°’: {value}, ì‹œìŠ¤í…œì´ ë°œê²¬í•œ ë¬¸ì œ: {error}, ê´€ë ¨ëœ ì‘ì„± ê·œì • (ì°¸ê³ ): {context} ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜¤ë¥˜ ë¦¬í¬íŠ¸ë¥¼ ìƒì„¸íˆ ì‘ì„±í•´ì£¼ì„¸ìš”."
    prompt = PromptTemplate.from_template(template)
    llm_chain = LLMChain(prompt=prompt, llm=llm)
    report = llm_chain.run({"field": error_info["field_name"], "value": error_info["user_value"], "error": error_info["error_message"], "context": context_from_db})
    return report

# --- 3. Streamlit UI êµ¬ì„± ---
st.title("ğŸ¤– AI ì„¸ê´€ ì„œë¥˜ ìë™ ê²€í†  ì‹œìŠ¤í…œ")
st.markdown("---")

vectordb, llm = load_resources()
uploaded_file = st.file_uploader("ê²€í† í•  ìˆ˜ì…ì‹ ê³ ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (PNG, JPG)", type=['png', 'jpg'])

if uploaded_file is not None and llm is not None:
    st.image(uploaded_file, caption='ì—…ë¡œë“œëœ ì‹ ê³ ì„œ ì´ë¯¸ì§€')
    
    if st.button("ê²€ì¦ ì‹œì‘"):
        with st.spinner("AIê°€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                response_text = parse_image_to_json_text(uploaded_file.getvalue(), llm)
                
                # ğŸš¨ --- ìˆ˜ì •ëœ ë¶€ë¶„: AIì˜ ì‘ë‹µì—ì„œ ìˆœìˆ˜ JSONë§Œ ì¶”ì¶œí•˜ëŠ” í•„í„° ë¡œì§ ---
                # ì‘ë‹µì—ì„œ ì²« '{'ì™€ ë§ˆì§€ë§‰ '}'ë¥¼ ì°¾ì•„ ê·¸ ì‚¬ì´ì˜ ë‚´ìš©ë§Œ ì˜ë¼ëƒ…ë‹ˆë‹¤.
                match = re.search(r"\{.*\}", response_text, re.DOTALL)
                if match:
                    json_string = match.group(0)
                    parsed_json = json.loads(json_string)
                    st.success("AI ë¶„ì„ ë° JSON ë³€í™˜ ì„±ê³µ!")
                    st.session_state['parsed_json'] = parsed_json
                    
                    with st.expander("AIê°€ ë¶„ì„í•œ JSON ë°ì´í„° ë³´ê¸°"):
                        st.json(parsed_json)
                else:
                    st.error("AIì˜ ì‘ë‹µì—ì„œ ìœ íš¨í•œ JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.text_area("LLM ì›ë³¸ ì‘ë‹µ ë‚´ìš©", response_text, height=200)
                    st.stop()
            except Exception as e:
                st.error(f"OCR/íŒŒì‹± ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.stop()

        if 'parsed_json' in st.session_state:
            with st.spinner("ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê²€ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                rules_df = load_rule_sheet('ìˆ˜ì…ì‹ ê³ ì„œ_ê²€ì¦ê·œì¹™.xlsx')
                if rules_df is not None:
                    errors = validate_document(st.session_state['parsed_json'], rules_df)
                    st.session_state['errors'] = errors
                    st.success("ê·œì¹™ ê²€ì¦ ì™„ë£Œ!")

        if 'errors' in st.session_state:
            errors = st.session_state['errors']
            st.markdown("---")
            st.subheader("âœ… ìµœì¢… ê²€ì¦ ê²°ê³¼")

            if not errors:
                st.balloons()
                st.success("ì¶•í•˜í•©ë‹ˆë‹¤! ë°œê²¬ëœ ì˜¤ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.error(f"ì´ {len(errors)}ê°œì˜ ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                with st.spinner("AIê°€ ì˜¤ë¥˜ì— ëŒ€í•œ ìƒì„¸ ë¦¬í¬íŠ¸ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    for error in errors:
                        report = get_intelligent_error_report(error, vectordb, llm)
                        st.markdown(report)
                        st.markdown("---")
